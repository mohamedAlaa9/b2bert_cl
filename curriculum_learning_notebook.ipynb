{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Learning for Arabic Dialect Classification\n",
    "## Reorganized and Modular Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'mladi (Python 3.10.19)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n mladi ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EvalPrediction,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support\n",
    "from preprocess import final_eliminations\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "# Import custom modules\n",
    "from bert_trainer import BertTrainer\n",
    "from config import Config, ExperimentConfig\n",
    "from data_utils import load_and_prepare_dataset, prepare_all_curriculum_stages\n",
    "from main_training import train_single_stage, train_curriculum_sequence, train_standalone_experiment\n",
    "from prepare_data import prepare_curriculum_data, analyze_dataset_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze dataset\n",
    "dataset_path = \"/home/ali.mekky/Documents/NLP/Project/NADI2024/subtask1/multilabel/NADIcombined_cleaned_MULTI_LABEL_MODIFIED_FINAL.csv\"\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and prepare dataset\n",
    "label_columns = ['Algeria', 'Bahrain', 'Egypt', 'Iraq', 'Jordan', 'Kuwait',\n",
    "       'Lebanon', 'Libya', 'Morocco', 'Oman', 'Palestine', 'Qatar',\n",
    "       'Saudi_Arabia', 'Sudan', 'Syria', 'Tunisia', 'UAE', 'Yemen']\n",
    "\n",
    "dataset = dataset[dataset['Computed'] == 'yes']\n",
    "dataset['dialect_sum'] = dataset[label_columns].sum(axis=1)\n",
    "\n",
    "# Filter rows with dialect_sum equal to 1\n",
    "rows_with_sum_1 = dataset[dataset['dialect_sum'] == 1]\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Samples with single dialect: {len(rows_with_sum_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Option A: Prepare All Curriculum Stages (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all curriculum learning stages\n",
    "# This creates stage files from stage_2.csv through stage_18.csv\n",
    "output_dir = \"/home/ali.mekky/Documents/NLP/Project/Cross-Country-Dialectal-Arabic-Identification/CL_stages\"\n",
    "\n",
    "stage_paths = prepare_curriculum_data(\n",
    "    dataset_path=dataset_path,\n",
    "    output_dir=output_dir,\n",
    "    computed_filter=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Option B: Train Standalone Experiment (Single Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a standalone experiment on stage 1 data\n",
    "train_standalone_experiment(\n",
    "    exp_num=27,\n",
    "    dataset_path=Config.get_stage_path(1),\n",
    "    model_name=\"CAMeL-Lab/bert-base-arabic-camelbert-mix\",\n",
    "    epochs=1,\n",
    "    batch_size=24,\n",
    "    threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Option C: Train Using Custom Configuration (Single Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "exp_config = ExperimentConfig(\n",
    "    exp_num=27,\n",
    "    stage=0,\n",
    "    model_name=\"CAMeL-Lab/bert-base-arabic-camelbert-mix\",\n",
    "    threshold=0.3,\n",
    "    batch_size=24,\n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "train_single_stage(exp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Option D: Full Curriculum Learning Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial stage (stage 0) from pretrained model\n",
    "exp_config_stage0 = ExperimentConfig(\n",
    "    exp_num=28,\n",
    "    stage=0,\n",
    "    model_name=\"CAMeL-Lab/bert-base-arabic-camelbert-mix\",\n",
    "    threshold=0.3,\n",
    "    batch_size=24,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "train_single_stage(exp_config_stage0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train subsequent stages using models from previous stages\n",
    "# This will train stages 1 through 15\n",
    "train_curriculum_sequence(\n",
    "    exp_num=28,\n",
    "    start_stage=1,  # Start from stage 1 (stage 0 already trained above)\n",
    "    end_stage=15,\n",
    "    epochs=2,\n",
    "    batch_size=24\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manual Curriculum Loop (Alternative to Option D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually loop through curriculum stages with full control\n",
    "for stage_num in range(1, 16):\n",
    "    exp_config = ExperimentConfig(\n",
    "        exp_num=28,\n",
    "        stage=stage_num,\n",
    "        threshold=0.3,\n",
    "        batch_size=24,\n",
    "        epochs=2,\n",
    "        use_previous_stage_model=True  # Load model from previous stage\n",
    "    )\n",
    "    \n",
    "    train_single_stage(exp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Direct Trainer Usage (Low-Level Access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For maximum control, use BertTrainer directly\n",
    "dataset_path = \"/home/ali.mekky/Documents/NLP/Project/Cross-Country-Dialectal-Arabic-Identification/CL_stages/stage_1.csv\"\n",
    "dev_path = \"/home/ali.mekky/Documents/NLP/Project/NADI2024/subtask1/dev/NADI2024_subtask1_dev2.tsv\"\n",
    "\n",
    "trainer = BertTrainer(\n",
    "    training_dataset_path=dataset_path,\n",
    "    model_name=\"CAMeL-Lab/bert-base-arabic-camelbert-mix\",\n",
    "    labels=Config.DIALECT_LABELS,\n",
    "    threshold=0.3,\n",
    "    exp_num=27\n",
    ")\n",
    "\n",
    "trainer.save_dir = f'./exp_{trainer.exp_num}'\n",
    "\n",
    "trainer.train(\n",
    "    num_train_epochs=1,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=24,\n",
    ")\n",
    "\n",
    "trainer.evaluate(dev_path=dev_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mladi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
